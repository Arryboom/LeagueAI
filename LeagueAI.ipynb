{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "#from PIL import ImageGrab\n",
    "import cv2\n",
    "import time\n",
    "from mss import mss\n",
    "import math\n",
    "from math import exp\n",
    "from random import randint\n",
    "from random import random\n",
    "\n",
    "\n",
    "\n",
    "#mouse control and window dimensions\n",
    "SCREEN_WIDTH = 1600\n",
    "SCREEN_HEIGHT = 1200\n",
    "MONITOR_WIDTH = 800\n",
    "MONITOR_HEIGHT = 600\n",
    "import win32api, win32con\n",
    "#Player Control\n",
    "click_cooldown = 0.5\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select model in the same folder as this script\n",
    "MODEL_NAME = 'LeagueAI_v3'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "#DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('training', 'LeagueAI_v2.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the frozen model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Champion helper classes\n",
    "# click a postion in the screen using x,y coordinates\n",
    "def click(x,y, attack):\n",
    "    win32api.SetCursorPos((x,y))\n",
    "    if attack == True:\n",
    "        win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN,x,y,0,0)\n",
    "        win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP,x,y,0,0)\n",
    "    else:\n",
    "        win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTDOWN,x,y,0,0)\n",
    "        win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTUP,x,y,0,0)\n",
    "def move_cursor_to(x,y):\n",
    "    win32api.SetCursorPos((x,y))\n",
    "# find the player character position marked as x,y (converting the boxes to a single point position)\n",
    "def find_box_xy(box):\n",
    "    playerwidth =  (box[3] - box[1])\n",
    "    playerheight = box[2] - box[0]\n",
    "    playerpos_y = (box[0] + playerheight/1.3)\n",
    "    playerpos_x = (box[1] + playerwidth/2)\n",
    "    return([playerpos_y, playerpos_x, playerheight, playerwidth])\n",
    "# find out in which state on object is\n",
    "def find_object_state(grid, minion_origin, player_origin, grid_width, grid_height):\n",
    "    x_object = (minion_origin[0])#/MONITOR_WIDTH)#*SCREEN_WIDTH\n",
    "    y_object = (minion_origin[1])#/MONITOR_HEIGHT)#*SCREEN_HEIGHT\n",
    "    x_player = (player_origin[0])#/MONITOR_WIDTH)#*SCREEN_WIDTH\n",
    "    y_player = (player_origin[1])#/MONITOR_HEIGHT)#*SCREEN_HEIGHT\n",
    "    #find difference to player in pixels\n",
    "    x_dif = -1*(x_player - x_object)\n",
    "    y_dif = (y_player - y_object)    \n",
    "    #transform pixels into states\n",
    "    state_x = round(x_dif/grid_width)\n",
    "    state_y = round(y_dif/grid_height)\n",
    "    return([state_x, state_y])\n",
    "# click a certain state given by x and y coordinate in the state grid\n",
    "def click_state(state_x, state_y, state_width, state_height, player_origin, attack):\n",
    "    x_click = (player_origin[0]/MONITOR_WIDTH)*SCREEN_WIDTH + state_x*(state_width/MONITOR_WIDTH)*SCREEN_WIDTH\n",
    "    y_click = (player_origin[1]/MONITOR_HEIGHT)*SCREEN_HEIGHT + (-1*state_y*(state_height/MONITOR_HEIGHT)*SCREEN_HEIGHT)\n",
    "    #click(int(x_click), int(y_click), attack)\n",
    "    #move_cursor_to(int(x_click), int(y_click))\n",
    "# set a certain state in the grid to a certain value to mark for example the type of unit in the state\n",
    "def set_array_pos(grid, x, y_in, value, x_grid_size_in, y_grid_size_in):\n",
    "    y = y_in*(-1)\n",
    "    # make sure that we do not overwrite the state of our player character in the grid\n",
    "    if not value == 1 and x == 0 and y == 0:\n",
    "        return grid\n",
    "    # resize grid in case we got uneven grid sizes\n",
    "    if x_grid_size_in%2==1:\n",
    "        x_grid_size = x_grid_size_in - 1\n",
    "    else:\n",
    "        x_grid_size = x_grid_size_in\n",
    "    if y_grid_size_in%2==1:\n",
    "        y_grid_size = y_grid_size_in -1\n",
    "    else:\n",
    "        y_grid_size = y_grid_size_in\n",
    "    x_pos = x + int(x_grid_size/2)\n",
    "    y_pos = y + int(y_grid_size/2)\n",
    "    grid[x_pos][y_pos] = value    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    \n",
    "    c_max_visible_dist = 20.0\n",
    "    c_close_dist_cutoff = 1.0 / 10.0\n",
    "    c_tower_safe_dist_cutoff = c_max_visible_dist / 3\n",
    "    c_max_hp = 1\n",
    "    c_game_time_beginning_cutoff = 0.5 *60 / 5\n",
    "    policy_gradient = np.array([1, 1, 1, 1]).T\n",
    "    delta_theta = np.zeros( (4,1) ).T\n",
    "    delta_R = []\n",
    "    R_i = 1\n",
    "    alpha = 0.1\n",
    "    R_ref = 1\n",
    "    \n",
    "    logistic_func_x_scale = 6\n",
    "    \n",
    "    # theta for the action:\n",
    "    # atk minion, atk tower, move to goal, retreat\n",
    "    # respectively\n",
    "    theta = np.zeros( (4,1) )\n",
    "    theta[0] = c_close_dist_cutoff\n",
    "    theta[1] = 1\n",
    "    theta[2] = 0.8 / (45*60/5)\n",
    "    theta[3] = 0.2\n",
    "class State:\n",
    "    \n",
    "    hp = 1.0\n",
    "    \n",
    "    cloest_minion_dist = 0\n",
    "    tower_dist = 0\n",
    "    \n",
    "    # game time counted in iterations or steps\n",
    "    game_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Intelligence\n",
    "def find_shortest_distance(unit_grid, unit_type):\n",
    "    distance = 10000 #no distance found\n",
    "    smallest_x = 0\n",
    "    smallest_y = 0\n",
    "    for i in range(3,len(unit_grid)-3):\n",
    "     for j in range(3,len(unit_grid[i])-3):\n",
    "        if unit_grid[i][j] == unit_type:#if minion found\n",
    "            cur_dist=math.sqrt(math.pow(i-int(len(unit_grid)/2),2)+math.pow(j-int(len(unit_grid[0])/2),2))\n",
    "            if cur_dist < distance:\n",
    "                distance = cur_dist\n",
    "                smallest_x = i-int(len(unit_grid)/2)\n",
    "                smallest_y = j-int(len(unit_grid[0])/2)\n",
    "    return [distance,smallest_x,-1*smallest_y]\n",
    "\n",
    "def minion_probability(closest_minion_distance,hp_frac):\n",
    "    #x: input to function\n",
    "    #1: max output value\n",
    "    #m: slope, calculated based on the max range in which an enemy is visible\n",
    "    #max_dist_enemy: maximum distance in which an enemy is\n",
    "    #x = closest_enemy_distance-closest_enemy_distance/5 #factor to increase minion threat level\n",
    "    #y = 7.954*math.pow(10,-5)*math.pow(x,4)-0.003558*math.pow(x,3)+0.05299*math.pow(x,2)-0.3257*x+0.9511\n",
    "    print(\"closest_miniont: \" + str(closest_minion_distance))\n",
    "    p = policy.theta[0]*hp_frac/closest_minion_distance\n",
    "    if   p > 1: return 1\n",
    "    elif p < 0: return 0\n",
    "    else      : return p\n",
    "\n",
    "def tower_probability(closest_tower_distance, hp_frac):\n",
    "    #y = 0.05657865 + (1.01699 - 0.05657865)/(1 + math.pow((closest_tower/6.996663),5.975224))\n",
    "    print(\"closest_tower: \" + str(closest_tower_distance))\n",
    "    \n",
    "    # reposition the curve the centre around [-6, +6]\n",
    "    closest_tower_distance = closest_tower_distance - 0.17    # center the curve the offset or cutoff dist\n",
    "    closest_tower_distance = closest_tower_distance - 0.5     # scale the range from  [0, 1] (or actually [-0.17, 1-0.17])\n",
    "    closest_tower_distance = closest_tower_distance * 6*2\n",
    "    print(\"closest_tower[-6, +6]: \" + str( (closest_tower_distance) ))\n",
    "    p = policy.theta[1]*hp_frac*(1/( 1+exp( -2*(closest_tower_distance+1)) ) - 1/( 1+exp( -10*(closest_tower_distance-3)) ) )\n",
    "    if   p > 1: return 1\n",
    "    elif p < 0: return 0\n",
    "    else      : return p\n",
    "\n",
    "def goal_probability():\n",
    "    if state.game_time < policy.c_game_time_beginning_cutoff:\n",
    "        return 1\n",
    "    else:\n",
    "        p = policy.theta[2] * state.game_time\n",
    "        if   p > 1: return 1\n",
    "        elif p < 0: return 0\n",
    "        else      : return p\n",
    "        \n",
    "def retreat_probability(hp_frac):\n",
    "    p = exp( policy.theta[3] / hp_frac ) - 1   \n",
    "    if   p > 1: return 1\n",
    "    elif p < 0: return 0\n",
    "    else      : return p\n",
    "\n",
    "\n",
    "def decide_action(minion_prob, tower_prob, goal_prob, retreat_prob):\n",
    "   total_prob = minion_prob + tower_prob + goal_prob + retreat_prob\n",
    "\n",
    "   attack_minion_cutoff = minion_prob / total_prob\n",
    "   attack_tower_cutoff = (minion_prob + tower_prob) / total_prob\n",
    "   goal_cutoff = (minion_prob + tower_prob + goal_prob) / total_prob\n",
    "   #retreat_cutoff = retreat_prob / total_prob\n",
    "\n",
    "   #roll random number and decide for one of the actions\n",
    "   rnd = random()\n",
    "   if   rnd < attack_minion_cutoff: return 0\n",
    "   elif rnd < attack_tower_cutoff:  return 1\n",
    "   elif rnd < goal_cutoff:          return 2\n",
    "   else:                            return 3\n",
    "\n",
    "def updateR_i():\n",
    "    R_i = policy.R_i\n",
    "    alpha = policy.alpha\n",
    "    \n",
    "    R_i = (1-alpha)*policy.R_i + alpha*np.dot(policy.policy_gradient, policy.delta_theta)\n",
    "    policy.R_i = R_i\n",
    "    \n",
    "    return R_i\n",
    "\n",
    "def updateR_ref(reward):\n",
    "    R_ref = policy.R_ref\n",
    "    alpha = policy.alpha\n",
    "    \n",
    "    R_ref = (1-alpha)*R_ref + alpha*reward\n",
    "    policy.R_ref = R_ref\n",
    "    \n",
    "def estimate_policy_gradient_FD(ticks):\n",
    "    #gets array with all actions in the last 5 seconds and the number of ticks/action done in the time frame\n",
    "    policy_grad = inv(policy.delta_theta.T * policy.delta_theta) * policy.delta_theta.T * policy.delta_R \n",
    "    return policy_grad    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Loop took: 0.03125309944152832 seconds\n",
      "=========Loop took: 1.905285120010376 seconds\n",
      "=========Loop took: 0.8075916767120361 seconds\n",
      "=========Loop took: 0.9480090141296387 seconds\n",
      "closest_miniont: 387.41942211302984\n",
      "closest_tower: 0.173259232729684\n",
      "closest_tower[-6, +6]: -5.960889207243792\n",
      "attack_minion_prob: [ 0.0002394]\n",
      "attack_tower_prob: [  4.55308877e-05]\n",
      "approach_enemy_base_prob: 1\n",
      "retreat_prob: 0.24065542736265177\n",
      "selected action: 3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (4,) and (1,4) not aligned: 4 (dim 0) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-da3537c00727>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    229\u001b[0m                   \u001b[1;31m#other params: attack_number_1/5 number of attacks since last reset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m                   \u001b[0mupdateR_i\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m                   \u001b[0mupdateR_ref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward_5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-91-a9b33b9995b9>\u001b[0m in \u001b[0;36mupdateR_i\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mR_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mR_i\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy_gradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta_theta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mR_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mR_i\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (4,) and (1,4) not aligned: 4 (dim 0) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "#Init variables\n",
    "vayne_last_found = time.time()\n",
    "MINION_REWARD = 10\n",
    "TOWER_REWARD = -100\n",
    "BLOCKED = -999\n",
    "policy = Policy()\n",
    "state = State()\n",
    "\n",
    "#reset variables for dicision making\n",
    "last_player_hp = 100\n",
    "attack_number_1 = 0\n",
    "attack_number_5 = 0\n",
    "hp_change_1 = 0\n",
    "hp_change_5 = 0\n",
    "last_reset_1 = time.time()\n",
    "last_reset_5 = time.time()\n",
    "tick_count_1 = 0\n",
    "tick_count_5 = 0\n",
    "game_start = time.time()\n",
    "\n",
    "sct = mss()\n",
    "# determine the size of the area to observe (the game)\n",
    "mon = {'top': 0, 'left': 0, 'width': SCREEN_WIDTH, 'height': SCREEN_HEIGHT}\n",
    "# timer to see how fast the loop is running\n",
    "last_time = time.time()\n",
    "with detection_graph.as_default():\n",
    "  with tf.Session(graph=detection_graph) as sess:\n",
    "    while True:\n",
    "      print('=========Loop took: {} seconds'.format(time.time()-last_time))\n",
    "      last_time = time.time()\n",
    "      #screen = cv2.resize(grab_screen(region=(0,40,1024,768)), (800,450))\n",
    "      #screen = np.array(ImageGrab.grab(bbox=(0,40,1024,768)))\n",
    "      # get screen recording and resize it to 800x450 pixels for output\n",
    "      sct.get_pixels(mon)\n",
    "      screen = Image.frombytes('RGB', (sct.width, sct.height), sct.image)\n",
    "      screen = np.array(screen)\n",
    "      screen = cv2.resize(screen, (MONITOR_WIDTH, MONITOR_HEIGHT))\n",
    "      image_np = screen\n",
    "      # ===================tensorflow code===============\n",
    "      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "      # Each box represents a part of the image where a particular object was detected.\n",
    "      boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "      # Each score represent how level of confidence for each of the objects.\n",
    "      # Score is shown on the result image, together with the class label.\n",
    "      scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "      classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "      # Actual detection.\n",
    "      (boxes, scores, classes, num_detections) = sess.run(\n",
    "          [boxes, scores, classes, num_detections],\n",
    "          feed_dict={image_tensor: image_np_expanded})                  \n",
    "      \n",
    "      # ====================================================  \n",
    "      # Visualization of the results of a detection\n",
    "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          np.squeeze(boxes),\n",
    "          np.squeeze(classes).astype(np.int32),\n",
    "          np.squeeze(scores),\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          min_score_thresh=0.30,\n",
    "          line_thickness=4)\n",
    "\n",
    "      #===================Player Character=======================\n",
    "      # detect hp:\n",
    "      hp_y_min = 563\n",
    "      hp_y_max = hp_y_min + 6\n",
    "      hp_x_min = int(MONITOR_WIDTH/2-123) #int(MONITOR_WIDTH/2-120)\n",
    "      hp_x_max = int(MONITOR_WIDTH/2+60)  \n",
    "      #print(image_np[hp_y_min][hp_x_min])\n",
    "      #print(image_np[hp_y_max][hp_x_max])\n",
    "      cv2.rectangle(image_np, (hp_x_min, hp_y_min),(hp_x_max,hp_y_max),(0, 0, 255), 1)\n",
    "      #cv2.circle(image_np,(hp_x_min, hp_y_min), 2, (0,100,100),1)  \n",
    "      green_pixels = 0\n",
    "      for x_hp in range(hp_x_min,hp_x_max,1):\n",
    "            for y_hp in range(hp_y_min,hp_y_max,1):\n",
    "                if image_np[y_hp][x_hp][1] > 15:\n",
    "                    green_pixels = green_pixels + 1\n",
    "      #print(\"Player HP: \" + str(green_pixels/((hp_x_max-hp_x_min-1)*(hp_y_max-hp_y_min-1))))\n",
    "      playerHP = green_pixels/((hp_x_max-hp_x_min-1)*(hp_y_max-hp_y_min-1))\n",
    "    \n",
    "      #Other variables\n",
    "      gameover = False\n",
    "      vayne_found = False\n",
    "      minion_count = 0\n",
    "      tower_count = 0\n",
    "      try:\n",
    "          if vayne_last_found + 10 < time.time():\n",
    "              click_state(randint(-2,2),randint(-2,2),w,h,player_origin,False);\n",
    "      except NameError:\n",
    "          print('player_origin not set yet')\n",
    "      for i,b in enumerate(boxes[0]):\n",
    "          if scores[0][i] >= 0.3:\n",
    "              #Vaynefound makes sure that the whole grid + decision proces only executed once per detection in case of a multi detection\n",
    "              if classes[0][i] == 1 and vayne_found == False:\n",
    "                  vayne_found = True;\n",
    "                  vayne_last_found = time.time()\n",
    "                  player_position = find_box_xy(boxes[0][i])\n",
    "                  #click(int(player_position[1]*SCREEN_WIDTH), int(player_position[0]*SCREEN_HEIGHT))\n",
    "                  #draw a circle where the character is\n",
    "                  player_origin = [int(player_position[1]*MONITOR_WIDTH), int(player_position[0]*MONITOR_HEIGHT)]\n",
    "                  cv2.circle(image_np, (player_origin[0], player_origin[1]), 2, (0, 0, 255), 2)\n",
    "                  #calculate the origin of the center rectangle under the character\n",
    "                  origin = [int(player_origin[0]+9)-int(player_position[2]*MONITOR_WIDTH/3), player_origin[1]-15,int(player_origin[0])+20, int(player_origin[1])+18]        \n",
    "                  cv2.rectangle(image_np,(origin[0], origin[1]),(origin[2], origin[3]), (0, 255, 0), 1)\n",
    "                  #create draw states\n",
    "                  w = int((origin[2] - origin[0]))\n",
    "                  h = int((origin[3] - origin[1]))\n",
    "                  grid_x = int(SCREEN_WIDTH/w)\n",
    "                  grid_y = int(SCREEN_HEIGHT/h)\n",
    "                  dim = (grid_x,grid_y)\n",
    "                  unit_grid = np.zeros(dim) \n",
    "                  #set the origin of the grid to be the player character represented by a 1\n",
    "                  #the grid goes from -grid_x/2 to grid_x/2 because the player is the center and everything left and under it is negative\n",
    "                  unit_grid = set_array_pos(unit_grid,0,0,1,grid_x,grid_y)\n",
    "                  #=======DETECT OBJECTS=======\n",
    "                  #2.Minions\n",
    "                  for j,k in enumerate(boxes[0]):\n",
    "                      if scores[0][j] >= 0.3:\n",
    "                          if classes[0][j] == 2:\n",
    "                              minion_count = minion_count + 1\n",
    "                              cur_minion_position = find_box_xy(boxes[0][j])\n",
    "                              cur_minion_origin = [int(cur_minion_position[1]*MONITOR_WIDTH), int(cur_minion_position[0]*MONITOR_HEIGHT)]\n",
    "                              cv2.circle(image_np, (cur_minion_origin[0], cur_minion_origin[1]), 2, (0, 0, 255), 2)\n",
    "                              #Find in which state in the unit_grid the minion is\n",
    "                              cur_minion_state = find_object_state(unit_grid, cur_minion_origin, player_origin, w, h)\n",
    "                              unit_grid = set_array_pos(unit_grid,cur_minion_state[0],cur_minion_state[1],2,grid_x,grid_y)\n",
    "                          #3.Towers\n",
    "                          if classes[0][j] == 3:\n",
    "                              tower_count = tower_count + 1\n",
    "                              cur_tower_position = find_box_xy(boxes[0][j])\n",
    "                              cur_tower_origin = [int(cur_tower_position[1]*MONITOR_WIDTH), int(cur_tower_position[0]*MONITOR_HEIGHT)]\n",
    "                              cv2.circle(image_np, (cur_tower_origin[0], cur_tower_origin[1]), 2, (0, 0, 255), 4)\n",
    "                              cur_tower_state = find_object_state(unit_grid, cur_tower_origin, player_origin, w, h)\n",
    "                              unit_grid = set_array_pos(unit_grid,cur_tower_state[0],cur_tower_state[1],3,grid_x,grid_y)                 \n",
    "                  \n",
    "                  #=============================\n",
    "                  #Visualize Objects and generate reward matrix#\n",
    "                  dim = (grid_x,grid_y)\n",
    "                  reward_grid = np.zeros(dim)\n",
    "                  for x in range(len(unit_grid)):\n",
    "                      for y in range(len(unit_grid[0])):\n",
    "                          #fill reward grid at the same time\n",
    "                          if unit_grid[x][y] == 1:\n",
    "                              #set the state at which the player is as blocked (-999 reward)\n",
    "                              reward_grid[x][y] = BLOCKED\n",
    "                              #===Paint player rectangle blue\n",
    "                              cv2.rectangle(image_np,(origin[0]+w*x-int(grid_x/2)*w, origin[1]+h*y-int(grid_y/2)*h),(origin[2]+w*x-int(grid_x/2)*w, origin[3]+h*y-int(grid_y/2)*h), (0, 255, 0), 1)\n",
    "                              cv2.rectangle(image_np,(origin[0]+2+w*x-int(grid_x/2)*w, origin[1]+2+h*y-int(grid_y/2)*h),(origin[2]-2+w*x-int(grid_x/2)*w, origin[3]-2+h*y-int(grid_y/2)*h), (0, 0, 255), 2)\n",
    "                          elif unit_grid[x][y] == 2:\n",
    "                              reward_grid[x][y] = MINION_REWARD\n",
    "                              #===MINIONS\n",
    "                              cv2.rectangle(image_np,(origin[0]+2+w*x-int(grid_x/2)*w, origin[1]+2+h*y-int(grid_y/2)*h),(origin[2]-2+w*x-int(grid_x/2)*w, origin[3]-2+h*y-int(grid_y/2)*h), (255, 0, 0), 2)\n",
    "                          elif unit_grid[x][y] == 3:\n",
    "                              reward_grid[x][y] = TOWER_REWARD\n",
    "                              #===TOWER\n",
    "                              cv2.rectangle(image_np,(origin[0]+2+w*x-int(grid_x/2)*w, origin[1]+2+h*y-int(grid_y/2)*h),(origin[2]-2+w*x-int(grid_x/2)*w, origin[3]-2+h*y-int(grid_y/2)*h), (255, 255, 255), 2)\n",
    "                          else:\n",
    "                              # draw empty rectangles green\n",
    "                              cv2.rectangle(image_np,(origin[0]+w*x-int(grid_x/2)*w, origin[1]+h*y-int(grid_y/2)*h),(origin[2]+w*x-int(grid_x/2)*w, origin[3]+h*y-int(grid_y/2)*h), (0, 255, 0), 1)\n",
    "                          \n",
    "                          \n",
    "                  #=======Hard Coded Decision Making========\n",
    "                  #print(shortest_distance)\n",
    "                  #if shortest_distance <= 5.0:\n",
    "                  #      #print('too close! run!')\n",
    "                  #      cv2.rectangle(image_np,(0,0), (w*5,h*5), (0, 255, 0), -1)\n",
    "                  #      if closest_x > 0 and closest_y > 0:\n",
    "                  #          click_state(-closest_x/abs(closest_x), -closest_y/abs(closest_y),w,h,player_origin,False)\n",
    "                  #elif shortest_distance < 8.0 and shortest_distance > 5.0:\n",
    "                  #      #print('attack!')\n",
    "                   #     cv2.rectangle(image_np,(0,0), (w*3,h*3), (0, 0, 255), -1)\n",
    "                   #     click_state(closest_x, closest_y,w,h,player_origin,True)\n",
    "                   ##     time.sleep(1)\n",
    "                  #elif shortest_distance > 8.0 and minion_count > 0:\n",
    "                  #      cv2.rectangle(image_np,(0,0), (w*3,h*3), (255, 0, 0), -1)\n",
    "                  #      #print('not in range, approaching!')\n",
    "                  #      click_state(closest_x, closest_y,w,h,player_origin,False)\n",
    "                  #else:\n",
    "                  #      cv2.rectangle(image_np,(0,0), (w*3,h*3), (0, 0, 0), -1)\n",
    "                  #      #print('no enemies found, run towards enemy base!')\n",
    "                  #      click_state(1, 1,w,h,player_origin,False)\n",
    "                    \n",
    "                        \n",
    "                  #=======Calculate the threat values of objects==========\n",
    "                  #get the info based on which the decisions shall be made\n",
    "                  [shortest_distance_minion, closest_minion_x, closest_minion_y] = find_shortest_distance(unit_grid, 2)\n",
    "                  [shortest_distance_tower, closest_tower_x, closest_tower_y] = find_shortest_distance(unit_grid, 3)\n",
    "                  shortest_distance_minion = shortest_distance_minion/math.sqrt(math.pow((grid_x/2),2)+math.pow((grid_y/2),2))\n",
    "                  shortest_distance_tower = shortest_distance_tower/math.sqrt(math.pow((grid_x/2),2)+math.pow((grid_y/2),2))\n",
    "                    \n",
    "                  attack_minion_prob = minion_probability(shortest_distance_minion, playerHP)\n",
    "                  attack_tower_prob = tower_probability(shortest_distance_tower, playerHP)\n",
    "                  approach_enemy_base_prob =  goal_probability()\n",
    "                  retreat_prob = retreat_probability(playerHP)\n",
    "                  print(\"attack_minion_prob: \" + str(attack_minion_prob))\n",
    "                  print(\"attack_tower_prob: \" + str(attack_tower_prob))\n",
    "                  print(\"approach_enemy_base_prob: \" + str(approach_enemy_base_prob))\n",
    "                  print(\"retreat_prob: \" + str(retreat_prob))\n",
    "                    \n",
    "                  #=======Make decision which action to take and to which state====\n",
    "                  #[state_x, state_y, action] = make_decision(playerHP, unit_grid, minion_value, tower_value);\n",
    "                  action = decide_action(attack_minion_prob, attack_tower_prob, approach_enemy_base_prob, retreat_prob)\n",
    "                  print(\"selected action: \" + str(action))\n",
    "                  ##=======Execute the action===========\n",
    "                  if action == 1:#Attack Minion\n",
    "                      click_state(closest_minion_x, closest_minon_y, w, h, player_origin, True)\n",
    "                      attack_number_1 = attack_number_1 + 1\n",
    "                      attack_number_5 = attack_number_5 + 1\n",
    "                  elif action == 2:#Attack Tower\n",
    "                      click_state(closest_tower_x, closest_tower_y, w, h, player_origin, True)\n",
    "                      attack_number_1 = attack_number_1 + 1.5\n",
    "                      attack_number_5 = attack_number_5 + 1.5\n",
    "                  elif action == 3:#Approach\n",
    "                      #Just move to the top right side\n",
    "                      click_state(1, 1, w, h, player_origin, False)\n",
    "                  else: #run away from the closest enemy by just running the the oposite direction as the enemy minion is\n",
    "                      click_state(2*(-closest_minion_x/math.abs(closest_minion_x)), 2*(-closest_minion_y/math.abs(closest_minion_y)), w, h, player_origin, False);\n",
    "                        \n",
    "                  #======Calculate Reward and feed it back======\n",
    "                  hp_change_1 = hp_change_1 + (- playerHP + last_player_hp) #add up the hp change until reset\n",
    "                  hp_change_5 = hp_change_5 +  (- playerHP + last_player_hp)\n",
    "                  tick_count_1 = tick_count_1 + 1\n",
    "                  tick_count_5 = tick_count_5 + 1\n",
    "                  last_player_hp = playerHP #update the current hp for the next loop\n",
    "                  #other params: attack_number_1/5 number of attacks since last reset\n",
    "                  \n",
    "                  updateR_i()\n",
    "                  updateR_ref(reward_5)\n",
    "                \n",
    "                  delta_R = policy.R_i - policy.R_ref\n",
    "                  #append the current action to delta_R[i]\n",
    "                  policy.delta_R.append(delta_R)\n",
    "                    \n",
    "                  #calculate reward average over the last 1 and 5 seconds                  \n",
    "                  #reset every 1 sec\n",
    "                  #if last_reset_1 + 1 < time.time():  \n",
    "                  #    reward_1 = 1-(hp_change_1/100) + attack_number_1/tick_count_1\n",
    "                  #    hp_change_1 = 0\n",
    "                  #    attack_number_1 = 0\n",
    "                  #    print(\"reward_1: \" + str(reward_1))\n",
    "                  #    tick_count_1 = 0\n",
    "                  #    last_reset_1 = time.time()\n",
    "                  ##reset every 5 sec\n",
    "                  if last_reset_5 + 5 < time.time():  \n",
    "                      reward_5 = 1-(hp_change_5/100) + attack_number_5/tick_count_5\n",
    "                      hp_change_5 = 0\n",
    "                      attack_number_5 = 0\n",
    "                      print(\" reward_5: \" + str(reward_5))\n",
    "                      last_reset_5 = time.time()\n",
    "                      #policy gradient estimation\n",
    "                      estimate_policy_gradient_FD(tick_count_5)\n",
    "                      policy.delta_R = []\n",
    "                      tick_count_5 = 0\n",
    "                  #===============FEEDBACK==================\n",
    "                  \n",
    "                  \n",
    "                                  \n",
    "      # ==================OPEN CV visualization=================\n",
    "      cv2.imshow('window',image_np)\n",
    "      if (cv2.waitKey(25) & 0xFF == ord('q')):\n",
    "          cv2.destroyAllWindows()\n",
    "          break\n",
    "      if gameover == True:\n",
    "          print('gameover')\n",
    "          cv2.destroyAllWindows()\n",
    "          break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
